{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30458,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Pipeline de Dados do Telegram**"
      ],
      "metadata": {
        "id": "zCmbqKGSndVS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Contexto:"
      ],
      "metadata": {
        "id": "pg4YEaKendVk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.1 Chatbot"
      ],
      "metadata": {
        "id": "glRrTnxrndVl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Um **chatbot** é um tipo de software que interage com usuários através de conversas automatizadas em plataformas de mensagens. Uma aplicação comum de **chatbots** é o seu uso no atendimento ao cliente, onde, de maneira geral, ajudam clientes a resolver problemas ou esclarecer dúvidas recorrentes antes mesmo que um atendente humano seja acionado."
      ],
      "metadata": {
        "id": "DDCVc7P5ndVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.2 Telegram"
      ],
      "metadata": {
        "id": "7VZEGkRIndVo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Telegram** é uma plataforma de mensagens instantâneas freeware (distribuído gratuitamente) e, em sua maioria, open source. É muito popular entre desenvolvedores por ser pioneiro na implantação da funcionalidade de criação de **chatbots**, que, por sua vez, permitem a criação de diversas automações."
      ],
      "metadata": {
        "id": "P2ButX00ndVp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.3 Arquitetura"
      ],
      "metadata": {
        "id": "U-qkfekCndVq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uma atividade analítica de interesse é a de realizar a análise exploratória de dados enviadas a um **chatbot** para responder perguntas como:\n",
        "\n",
        "1. Qual o horário que os usuários mais acionam o bot?\n",
        "2. Qual o problema ou dúvida mais frequente?\n",
        "3. O bot está conseguindo resolver os problemas ou esclarecer as dúvidas?"
      ],
      "metadata": {
        "id": "lzNie7cTndVr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Portanto, vamos construir um pipeline de dados que ingira, processe, armazene e exponha mensagens de um grupo do **Telegram** para que profissionais de dados possam realizar análises. A arquitetura proposta é dividida em duas: transacional, no **Telegram**, onde os dados são produzidos, e analítica, na Amazon Web Services (AWS), onde os dados são analisados.\n",
        "\n",
        "![](http://github.com/nildomuniz/ebac-analista-dados/blob/main/9.Big_Data_LataLake_AWS/modulo_44_arch.png?raw=true)"
      ],
      "metadata": {
        "id": "VJXRbzwmndVs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **AWS | Ingestão**\n",
        "\n",
        "Uma requisição HTTP com o conteúdo da mensagem em seu payload é recebia pelo AWS API Gateway que, por sua vez, as redireciona para o AWS Lambda , servindo assim como seu gatilho. Já o AWS Lambda recebe o payload da requisição em seu parâmetro event, salva o conteúdo em um arquivo no formato JSON (original, mesmo que o payload) e o armazena no AWS S3 particionado por dia."
      ],
      "metadata": {
        "id": "29-_c5O0ndVt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **AWS | ETL**\n",
        "\n",
        "Uma vez ao dia, o AWS Event Bridge aciona o AWS Lambda que processa todas as mensagens do dia anterior (atraso de um dia ou D-1), denormaliza o dado semi-estruturado típico de arquivos no formato JSON, salva o conteúdo processado em um arquivo no formato Apache Parquet e o armazena no AWS S3 particionado por dia."
      ],
      "metadata": {
        "id": "T_GN18t4ndVu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **AWS | Apresentação**\n",
        "\n",
        "Por fim, uma tabela do AWS Athena é apontada para o bucket do AWS S3 que armazenao dado processado: denormalizado, particionado e orientado a coluna. Profissionais de\n",
        "dados podem então executar consultas analíticas (agregações, ordenações, etc.) na tabela utilizando o SQL para a extração de insights."
      ],
      "metadata": {
        "id": "g6SI9-hgndVv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Telegram\n",
        "\n",
        "O **Telegram** representa a fonte transacional de dados do nosso pipeline de dados. Nesta etapa, vamos criar um grupo, criar um **bot** e adiciona-lo ao grupo recém criado. O bot então captará todas as mensagens enviadas no grupo. As mensagens pode ser acessadas através da API (application programming interface) de bots dos **Telegram** (documentação neste [link](https://core.telegram.org/bots/api)."
      ],
      "metadata": {
        "id": "Lc3UVFivndVv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.1 Conta**\n",
        "\n",
        "Para criar uma conta no **Telegram**, basta fazer o download do aplicativo na loja de aplicativos do seu smartphone. Uma vez criada, acesse sua conta através da versão web da\n",
        "plataforma de mensagens neste [link](https://web.telegram.org/k/)."
      ],
      "metadata": {
        "id": "Hzvn7CRSndVw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.2 Bot**\n",
        "\n",
        "Para criar um bot:\n",
        "1. Abra o chat com o BotFather ;\n",
        "2. Digite /newbot ;\n",
        "3. Digite o nome do bot;\n",
        "4. Digite o nome de usuário do bot (precisa terminar com sufixo _bot );\n",
        "5. Salve o token de acesso a API HTTP em um local seguro.\n",
        "\n",
        "Para conferir o token novamente:\n",
        "\n",
        "1. Abra o chat com o BotFather ;\n",
        "2. Digite /mybots ;\n",
        "3. Selecione o bot pelo seu nome de usuário;\n",
        "4. Selecione API Token .\n",
        "\n",
        "Por fim, precisamos ativiar o bot.\n",
        "1. Abra o chat com o bot;\n",
        "2. Selecione start ."
      ],
      "metadata": {
        "id": "1IcI6J_EndVw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.3 Grupo**\n",
        "\n",
        "Para criar um novo grupo:\n",
        "1. Aperte o botão com o ícone de um lápis;\n",
        "2. Selecione New Group ;\n",
        "3. Busque e selecione o bot recém criado pelo seu nome;\n",
        "4. Aperte o botão com o ícone de uma seta;\n",
        "5. Digite o nome do grupo.\n",
        "\n",
        "Com o grupo criado, vamos adicionar o bot como administrador para que ele possa receber todas as mensagens do grupo. Uma outra opção seria desabilitar o seu modo de privacidade.\n",
        "\n",
        "1. Abra o chat do grupo recém criado;\n",
        "2. Abra o perfil do grupo;\n",
        "3. Aperte o botão com o ícone de um lápis;\n",
        "4. No campo de descrição do grupo escreva: Atenção, todas as mensagens são armazenadas pelo bot do grupo;\n",
        "5. Selecione Administrators;\n",
        "6. Aperte o botão com o ícone de um usuário;\n",
        "7. Selecione o bot.\n",
        "8. Aperte o botão com o ícone de um check.\n",
        "\n",
        "Por fim, vamos configurar o bot para que ele não possa ser adicionado a outros grupos:\n",
        "\n",
        "1. Abra o chat com o BotFather ;\n",
        "2. Digite /mybots ;\n",
        "3. Selecione o bot pelo seu nome de usuário;\n",
        "4. Selecione Bot Settings ;\n",
        "5. Selecione Allow Groups? ;\n",
        "6. Selecione Turn groups off .\n",
        "\n",
        "Com tudo pronto, envie algumas mensagens no grupo."
      ],
      "metadata": {
        "id": "tPcSJynyndVw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.4 Bot API**\n",
        "\n",
        "As mensagens captadas por um bot podem ser acessadas via API. A única informação necessária é o token de acesso fornecido pelo BotFather na criação do bot.\n",
        "\n",
        "> **Nota:** A documentação completa da API pode ser encontrada neste [link](https://core.telegram.org/bots/api)."
      ],
      "metadata": {
        "id": "u6F375WEndVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "token = getpass()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-23T17:08:37.359154Z",
          "iopub.execute_input": "2023-04-23T17:08:37.360256Z",
          "iopub.status.idle": "2023-04-23T17:08:41.252566Z",
          "shell.execute_reply.started": "2023-04-23T17:08:37.360202Z",
          "shell.execute_reply": "2023-04-23T17:08:41.251026Z"
        },
        "trusted": true,
        "id": "ot5nE6sLndVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A url base é comum a todos os métodos da API."
      ],
      "metadata": {
        "id": "I57s5SbAndV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import requests\n",
        "base_url = f'https://api.telegram.org/bot{token}'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-23T17:08:51.72797Z",
          "iopub.execute_input": "2023-04-23T17:08:51.728983Z",
          "iopub.status.idle": "2023-04-23T17:08:51.734782Z",
          "shell.execute_reply.started": "2023-04-23T17:08:51.728933Z",
          "shell.execute_reply": "2023-04-23T17:08:51.733279Z"
        },
        "trusted": true,
        "id": "Aex1qg2ondV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **getMe**\n",
        "\n",
        "O método getMe retorna informações sobre o bot."
      ],
      "metadata": {
        "id": "2tB2oG9AndV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = requests.get(url=f'{base_url}/getMe')\n",
        "print(f'{base_url}/getMe')\n",
        "print(json.dumps(json.loads(response.text), indent=2))"
      ],
      "metadata": {
        "id": "62wYCGqVndV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://github.com/murilovalenso/Projeto-Pipeline-de-Dados-Telegram/blob/main/Projetos/1%20-%20getMe.png?raw=true)"
      ],
      "metadata": {
        "id": "XQfUK4IYndV1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **getUpdates**\n",
        "\n",
        "O método getMe retorna as mensagens captadas pelo bot."
      ],
      "metadata": {
        "id": "nUoCQ5OgndV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = requests.get(url=f'{base_url}/getUpdates')\n",
        "print(json.dumps(json.loads(response.text), indent=2))"
      ],
      "metadata": {
        "id": "jTCoru9EndV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://github.com/murilovalenso/Projeto-Pipeline-de-Dados-Telegram/blob/main/Projetos/2-%20getUpdates.png?raw=true)"
      ],
      "metadata": {
        "id": "lUTkyJ5-ndV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Ingestão\n",
        "\n",
        "A etapa de ingestão é responsável, como seu o próprio nome diz, pela ingestão dos dados transacionais em ambientes analíticos. De maneira geral, o dado ingerido é persistido no formato mais próximo do original, ou seja, nenhuma transformação é realizada em seu conteúdo ou estrutura (schema). Como exemplo, dados de uma API web que segue o formato REST (representational state transfer) são entregues, logo, persistidos, no formato JSON.\n",
        "\n",
        "> Persistir os dados em seu formato original trás muitas vantagens, como a possibilidade de reprocessamento."
      ],
      "metadata": {
        "id": "FY39qfoOndV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pode ser conduzida de duas formas:\n",
        "\n",
        "* **Batch**: blocos de dados são ingeridos em uma frequência bem definida, geralmente na escala de horas ou dias;\n",
        "* **Streaming**: dados são ingeridos conforme são produzidos e disponibilizados.\n",
        "\n",
        "No projeto, as mensagens capturadas pelo bot podem ser ingeridas através da API web de bots do Telegram, portanto são fornecidos no formato JSON. Como o Telegram retem mensagens por apenas 24h em seus servidores, a ingestão via streaming é a mais indicada. Para que seja possível esse tipo de ingestão seja possível, vamos utilizar um webhook (gancho web), ou seja, vamos redirecionar as mensagens automaticamente para outra API web.\n",
        "\n",
        "Sendo assim, precisamos de um serviço da AWS que forneça um API web para receber os dados redirecionados, o AWS API Gateway (documentação neste link). Dentre suas diversas funcionalidades, o AWS API Gateway permite o redirecionamento do dado recebido para outros serviços da AWS. Logo, vamos conecta-lo ao AWS Lambda, que pode sua vez, irá armazenar o dado em seu formato original (JSON) em um bucket do **AWS S3**.\n",
        "\n",
        "> Sistemas que reagem a eventos são conhecidos como event-driven.\n",
        "\n",
        "\n",
        "Portanto, precisamos:\n",
        "\n",
        "* Criar um bucket no AWS S3;\n",
        "* Criar uma função no AWS Lambda;\n",
        "* Criar uma API web no AWS API Gateway;\n",
        "* Configurar o webhook da API de bots do **Telegram**."
      ],
      "metadata": {
        "id": "asvUZSUendV3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Criando um Bucket no AWS**:\n",
        "\n",
        "![](https://github.com/murilovalenso/Projeto-Pipeline-de-Dados-Telegram/blob/main/Prints%201/1-bucket_criado.png?raw=true)"
      ],
      "metadata": {
        "id": "kJRshOuHndV3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Criando uma função no AWS Lambda:**\n",
        "\n",
        "![](https://github.com/murilovalenso/Projeto-Pipeline-de-Dados-Telegram/blob/main/Prints%201/2-lambda_criado.png?raw=true)"
      ],
      "metadata": {
        "id": "2OwnCQz6ndV3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.1 AWS S3**\n",
        "\n",
        "Na etapa de **ingestão**, o AWS S3 tem a função de passivamente armazenar as mensagens captadas pelo bot do **Telegram** no seu formato original: JSON. Para tanto, basta a criação de um bucket. Como padrão, vamos adicionar o sufixo -raw ao seu nome (vamos seguir esse padrão para todos os serviços desta camada).\n",
        "\n",
        "> **Nota**: um data lake é o nome dado a um repositório de um grande volume dados. É organizado em zonas que armazenam replicadas dos dados em diferentes níveis de processamento. A nomenclatura das zonas varia, contudo, as mais comuns são: raw e enriched ou bronze, silver e gold."
      ],
      "metadata": {
        "id": "Ag-XhW9indV3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.2 AWS Lambda**\n",
        "\n",
        "Na etapa de ingestão, o AWS Lambda tem a função de ativamente persistir as mensagens captadas pelo bot do Telegram em um bucket do AWS S3. Para tanto vamos criar uma função que opera da seguinte forma:\n",
        "\n",
        "* Recebe a mensagem no parâmetro event;\n",
        "* Verifica se a mensagem tem origem no grupo do **Telegram** correto;\n",
        "* Persiste a mensagem no formato JSON no bucket do AWS S3;\n",
        "* Retorna uma mensagem de sucesso (código de retorno HTTP igual a 200) a API de bots do **Telegram**.\n",
        "\n",
        "> **Nota**: No **Telegram**, restringimos a opção de adicionar o bot a grupos, contudo, ainda é possível iniciar uma conversa em um chat privado.\n",
        "\n",
        "O código da função:"
      ],
      "metadata": {
        "id": "ofo8rl1AndV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import logging\n",
        "from datetime import datetime, timezone\n",
        "\n",
        "import boto3\n",
        "\n",
        "\n",
        "def lambda_handler(event: dict, context: dict) -> dict:\n",
        "\n",
        "  '''\n",
        "  Recebe uma mensagens do Telegram via AWS API Gateway, verifica no\n",
        "  seu conteúdo se foi produzida em um determinado grupo e a escreve,\n",
        "  em seu formato original JSON, em um bucket do AWS S3.\n",
        "  '''\n",
        "\n",
        "  # vars de ambiente\n",
        "\n",
        "  BUCKET = os.environ['AWS_S3_BUCKET']\n",
        "  TELEGRAM_CHAT_ID = int(os.environ['TELEGRAM_CHAT_ID'])\n",
        "\n",
        "  # vars lógicas\n",
        "\n",
        "  tzinfo = timezone(offset=timedelta(hours=-3))\n",
        "  date = datetime.now(tzinfo).strftime('%Y-%m-%d')\n",
        "  timestamp = datetime.now(tzinfo).strftime('%Y%m%d%H%M%S%f')\n",
        "\n",
        "  filename = f'{timestamp}.json'\n",
        "\n",
        "  # código principal\n",
        "\n",
        "  client = boto3.client('s3')\n",
        "\n",
        "  try:\n",
        "\n",
        "  # message = json.loads(event[\"body\"])\n",
        "    message = event\n",
        "    chat_id = message[\"message\"][\"chat\"][\"id\"]\n",
        "\n",
        "    if chat_id == TELEGRAM_CHAT_ID:\n",
        "\n",
        "      with open(f\"/tmp/{filename}\", mode='w', encoding='utf8') as fp:\n",
        "        json.dump(message, fp)\n",
        "\n",
        "      client.upload_file(f'/tmp/{filename}', BUCKET, f'telegram/context_date={date}/{filename}')\n",
        "\n",
        "  except Exception as exc:\n",
        "      logging.error(msg=exc)\n",
        "      return dict(statusCode=\"500\")\n",
        "\n",
        "  else:\n",
        "      return dict(statusCode=\"200\")"
      ],
      "metadata": {
        "id": "N0iOXcN3ndV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para que a função funcione corretamente, algumas configurações precisam ser realizadas.\n",
        "\n",
        "* **Variáveis de ambiente**\n",
        "\n",
        "Note que o código exige a configuração de duas variáveis de ambiente: AWS_S3_BUCKET com o nome do bucket do AWS S3 e TELEGRAM_CHAT_ID com o id do chat do grupo do **Telegram**. Para adicionar variáveis de ambiente em uma função do AWS Lambda, basta acessar configurações -> variáveis de ambiente no console da função.\n",
        "\n",
        "> **Nota**: Variáveis de ambiente são excelentes formas de armazenar informações sensíveis.\n"
      ],
      "metadata": {
        "id": "iiGJZIEGndV4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Variáveis de ambiente criadas**:\n",
        "\n",
        "![](https://github.com/murilovalenso/Projeto-Pipeline-de-Dados-Telegram/blob/main/Prints%201/4-Variaveis%20de%20ambiente_criada.png?raw=true)"
      ],
      "metadata": {
        "id": "KThGFZMTndV4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Permissão**\n",
        "\n",
        "Por fim, precisamos adicionar a permissão de escrita no bucket do AWS S3 para a função do AWS Lambda no AWS IAM.\n",
        "\n",
        "![](https://github.com/murilovalenso/Projeto-Pipeline-de-Dados-Telegram/blob/main/Prints%201/5%20-politicaAnexada.png?raw=true)"
      ],
      "metadata": {
        "id": "NTqmrI-VndV5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Configurando Evento de Teste no Lambda para conferir integração no S3**\n",
        "\n",
        "![](https://github.com/murilovalenso/Projeto-Pipeline-de-Dados-Telegram/blob/main/Prints%201/7-lambdaExecutado.png?raw=true)\n",
        "\n",
        "> **Verificando no S3**\n",
        "\n",
        "![](https://github.com/murilovalenso/Projeto-Pipeline-de-Dados-Telegram/blob/main/Prints%201/9-%20telegramArquivo%20(2).png?raw=true)\n",
        "\n",
        "> **Evento de teste bem sucedido**\n",
        "\n",
        "![](https://github.com/murilovalenso/Projeto-Pipeline-de-Dados-Telegram/blob/main/Prints%201/12-atualizadorecomentado.Json.png?raw=true)"
      ],
      "metadata": {
        "id": "H-3sG5YIndV5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **3.3 AWS API Gateway**\n",
        "\n",
        "Na etapa de **ingestão**, o AWS API Gateway tem a função de receber as mensagens captadas pelo bot do **Telegram**, enviadas via webhook, e iniciar uma função do AWS Lambda, passando o conteúdo da mensagem no seu parâmetro event. Para tanto vamos criar uma API e configurá-la como gatilho da função do AWS Lambda:\n",
        "\n",
        "* Acesse o serviço e selecione: Create API -> REST API;\n",
        "* Insira um nome, como padrão, um que termine com o sufixo -api;\n",
        "* Selecione: Actions -> Create Method -> POST;\n",
        "* Na tela de setup:\n",
        "    * Selecione Integration type igual a Lambda Function;\n",
        "    * Habilite o Use Lambda Proxy integration;\n",
        "    * Busque pelo nome a função do AWS Lambda.\n",
        "    \n",
        "Podemos testar a integração com o AWS Lambda através da ferramenta de testes do serviço. Por fim, vamos fazer a implantação da API e obter o seu endereço web.\n",
        "\n",
        "* Selecione: Actions -> Deploy API;\n",
        "* Selecione: New Stage para Deployment stage;\n",
        "* Adicione dev como Stage name.\n",
        "\n",
        "\n",
        "Copie o a url gerada na variável aws_api_gateway_url."
      ],
      "metadata": {
        "id": "mPtM5rcRndV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aws_api_gateway_url = getpass()"
      ],
      "metadata": {
        "id": "j5YaLwrKndV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Criando uma API no AWS API Gateway e a conectando a função do AWS Lambda, conforme apresentado na aula.**\n",
        "\n",
        "![](https://github.com/murilovalenso/Projeto-Pipeline-de-Dados-Telegram/blob/main/Prints%201/13-apiCriada.png?raw=true)"
      ],
      "metadata": {
        "id": "agMyrRb9ndV7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **3.4 Telegram**\n",
        "\n",
        "Vamos configurar o webhook para redirecionar as mensagens para a url do AWS API Gateway.\n",
        "\n",
        "* **setWebhook**\n",
        "\n",
        "O método setWebhook configura o redirecionamento das mensagens captadas pelo bot para o endereço *web* do paramametro *url*.\n",
        "\n",
        "> **Nota**: os métodos *getUpdates* e *setWebhook* são mutualmente exclusivos, ou seja, enquanto o *webhook* estiver ativo, o método *getUpdates* não funcionará. Para desativar o *webhook*, basta utilizar o método *deleteWebhook*."
      ],
      "metadata": {
        "id": "6sVBaiBTndV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = requests.get(url=f'{base_url}/setWebhook?url={aws_api_gateway_url}')\n",
        "\n",
        "print(json.dumps(json.loads(response.text), indent=2))"
      ],
      "metadata": {
        "id": "t8XfhU2ZndV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://github.com/murilovalenso/Projeto-Pipeline-de-Dados-Telegram/blob/main/Projetos/3-%20setWebhook.png?raw=true)"
      ],
      "metadata": {
        "id": "nzXFUobendV8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **getWebhookInfo**\n",
        "\n",
        "O método *getWebhookInfo* retorna as informações sobre o *webhook* configurado."
      ],
      "metadata": {
        "id": "hUCIslgVndV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = requests.get(url=f'{base_url}/getWebhookInfo')\n",
        "\n",
        "print(json.dumps(json.loads(response.text), indent=2))"
      ],
      "metadata": {
        "id": "jduCsmoRndV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://github.com/murilovalenso/Projeto-Pipeline-de-Dados-Telegram/blob/main/Projetos/4-%20getWebhookInfo.png?raw=true)"
      ],
      "metadata": {
        "id": "5IVSiDLjndV9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. ETL\n",
        "\n",
        "A etapa de **extração, transformação e carregamento** (do inglês extraction, transformation and load ou **ETL**) é uma etapa abrangente responsável pela manipulação dos dados ingeridos de sistemas transacionais, ou seja, já persistidos em camadas cruas ou raw de sistemas analíticos. Os processos conduzidos nesta etapa variam bastante de acordo com a área da empresa, do volume/variedade/velocidade do dado consumido, etc. Contudo, em geral, o dado cru ingerido passa por um processo recorrente de *data wrangling* onde o dado é limpo, deduplicado, etc. e persistido com técnicas de particionamento, orientação a coluna e compressão. Por fim, o dado processado está pronto para ser analisado por profissionais de dados.\n",
        "\n",
        "No projeto, as mensagens de um único dia, persistidas na camada cru, serão compactas em um único arquivo, orientado a coluna e comprimido, que será persistido em uma camada enriquecida. Além disso, durante este processo, o dado também passará por etapas de data *wrangling*.\n",
        "\n",
        "Para isso, vamos utilizar uma função do *AWS Lambda* como motor de processamento e um bucket do *AWS S3* como camada enriquecida para a persistência do dado processado. Para garantir a recorrência, vamos configurar uma regra do *AWS Event Bridge* como gatilho diáro da função."
      ],
      "metadata": {
        "id": "iftPw3HkndV9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **4.1 AWS S3**\n",
        "\n",
        "Na etapa de ETL, o AWS S3 tem a função de passivamente armazenar as mensagens processadas de um dia em um único arquivo no formato Parquet. Para tanto, basta a criação de um bucket. Como padrão, vamos adicionar o sufixo -enriched ao seu nome (vamos seguir esse padrão para todos os serviços desta camada).\n",
        "\n",
        "> **Nota**: um data lake é o nome dado a um repositório de um grande volume dados. É organizado em zonas que armazenam replicadas dos dados em diferentes níveis de processamento. A nomenclatura das zonas varia, contudo, as mais comuns são: raw e enriched ou bronze, silver e gold."
      ],
      "metadata": {
        "id": "Mcf6Oj7nndV-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Bucket enriched criado:**\n",
        "\n",
        "![](https://github.com/murilovalenso/Projeto-Pipeline-de-Dados-Telegram/blob/main/Prints%201/17-bucketEnriched.png?raw=true)"
      ],
      "metadata": {
        "id": "NvYOempWndV-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.2 AWS Lambda**\n",
        "\n",
        "Na etapa de **ETL**, o AWS Lambda tem a função de ativamente processar as mensagens captadas pelo bot do **Telegram**, persistidas na camada cru no bucket do AWS S3, e persisti-las na camada enriquecida, também em um bucket do AWS S3. Logo, vamos criar uma função que opera da seguinte forma:\n",
        "\n",
        "* Lista todos os arquivos JSON de uma única participação da camada crua de um bucket do AWS S3;\n",
        "* Para cada arquivo listado:\n",
        "    * Faz o download do arquivo e carrega o conteúdo da mensagem;\n",
        "    * Executa uma função de data wrangling;\n",
        "    * Cria uma tabela do PyArrow e a contatena com as demais.\n",
        "* Persiste a tabela no formato Parquet na camada enriquecida em um bucket do AWS S3.\n",
        "\n",
        "> **Nota**: O fato de utilizarmos duas camadas de armazenamento e processamento, permite que possamos reprocessar os dados crus de diversas maneiras, quantas vezes forem preciso.\n",
        "\n",
        "> **Nota**: Atente-se ao fato de que a função processa as mensagens do dia anterior (D-1).\n"
      ],
      "metadata": {
        "id": "wahq-tU3ndV-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **O código da função:**"
      ],
      "metadata": {
        "id": "SeUJtF0QndV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import logging\n",
        "from datetime import datetime, timedelta, timezone\n",
        "\n",
        "import boto3\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "\n",
        "\n",
        "def lambda_handler(event: dict, context: dict) -> bool:\n",
        "\n",
        "  '''\n",
        "  Diariamente é executado para compactar as diversas mensagensm, no formato\n",
        "  JSON, do dia anterior, armazenadas no bucket de dados cru, em um único\n",
        "  arquivo no formato PARQUET, armazenando-o no bucket de dados enriquecidos\n",
        "  '''\n",
        "\n",
        "  # vars de ambiente\n",
        "\n",
        "  RAW_BUCKET = os.environ['AWS_S3_BUCKET']\n",
        "  ENRICHED_BUCKET = os.environ['AWS_S3_ENRICHED']\n",
        "\n",
        "  # vars lógicas\n",
        "\n",
        "  tzinfo = timezone(offset=timedelta(hours=-3))\n",
        "  date = (datetime.now(tzinfo) - timedelta(days=1)).strftime('%Y-%m-%d')\n",
        "  timestamp = datetime.now(tzinfo).strftime('%Y%m%d%H%M%S%f')\n",
        "\n",
        "  # código principal\n",
        "\n",
        "  table = None\n",
        "  client = boto3.client('s3')\n",
        "\n",
        "  try:\n",
        "\n",
        "      response = client.list_objects_v2(Bucket=RAW_BUCKET, Prefix=f'telegram/context_date={date}')\n",
        "\n",
        "      for content in response['Contents']:\n",
        "\n",
        "        key = content['Key']\n",
        "        client.download_file(RAW_BUCKET, key, f\"/tmp/{key.split('/')[-1]}\")\n",
        "\n",
        "        with open(f\"/tmp/{key.split('/')[-1]}\", mode='r', encoding='utf8') as fp:\n",
        "\n",
        "          data = json.load(fp)\n",
        "          data = data[\"message\"]\n",
        "\n",
        "        parsed_data = parse_data(data=data)\n",
        "        iter_table = pa.Table.from_pydict(mapping=parsed_data)\n",
        "\n",
        "        if table:\n",
        "\n",
        "          table = pa.concat_tables([table, iter_table])\n",
        "\n",
        "        else:\n",
        "\n",
        "          table = iter_table\n",
        "          iter_table = None\n",
        "\n",
        "      pq.write_table(table=table, where=f'/tmp/{timestamp}.parquet')\n",
        "      client.upload_file(f\"/tmp/{timestamp}.parquet\", ENRICHED_BUCKET, f\"telegram/context_date={date}/{timestamp}.parquet\")\n",
        "\n",
        "      return True\n",
        "\n",
        "  except Exception as exc:\n",
        "      logging.error(msg=exc)\n",
        "      return False"
      ],
      "metadata": {
        "id": "fIcvWNbvndV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **O código da função de data wrangling:**"
      ],
      "metadata": {
        "id": "Ahoap0FNndV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_data(data: dict) -> dict:\n",
        "\n",
        "  date = datetime.now().strftime('%Y-%m-%d')\n",
        "  timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "  parsed_data = dict()\n",
        "\n",
        "  for key, value in data.items():\n",
        "\n",
        "      if key == 'from':\n",
        "          for k, v in data[key].items():\n",
        "              if k in ['id', 'is_bot', 'first_name']:\n",
        "                parsed_data[f\"{key if key == 'chat' else 'user'}_{k}\"] = [v]\n",
        "\n",
        "      elif key == 'chat':\n",
        "          for k, v in data[key].items():\n",
        "              if k in ['id', 'type']:\n",
        "                parsed_data[f\"{key if key == 'chat' else 'user'}_{k}\"] = [v]\n",
        "\n",
        "      elif key in ['message_id', 'date', 'text']:\n",
        "          parsed_data[key] = [value]\n",
        "\n",
        "  if not 'text' in parsed_data.keys():\n",
        "    parsed_data['text'] = [None]\n",
        "\n",
        "  return parsed_data"
      ],
      "metadata": {
        "id": "pV_YYdDWndWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Função criada**\n",
        "\n",
        "![](https://github.com/murilovalenso/Projeto-Pipeline-de-Dados-Telegram/blob/main/Prints%201/18-funcaoEnriched.png?raw=true)"
      ],
      "metadata": {
        "id": "C6oLVn9dndWA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para que a função funcione corretamente, algumas configurações precisam ser realizadas."
      ],
      "metadata": {
        "id": "Eb5-ypbjndWA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Variáveis de ambiente**\n",
        "\n",
        "Note que o código exige a configuração de duas variáveis de ambiente: **AWS_S3_BUCKET** e **AWS_S3_ENRICHED** com os nomes dos bucket do AWS S3 da camada cru e enriquecida, respectivamente. Para adicionar variáveis de ambiente em uma função do AWS Lambda, basta acessar configurações -> variáveis de ambiente no console da função.\n",
        "\n",
        "> **Variável de ambiente criada:**\n",
        "\n",
        "![](https://github.com/murilovalenso/Projeto-Pipeline-de-Dados-Telegram/blob/main/Prints%201/20-variaveisAmbiente_enriched.png?raw=true)"
      ],
      "metadata": {
        "id": "ufDUbjSindWB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Permissão**\n",
        "\n",
        "Precisamos adicionar a permissão de escrita nos buckets do AWS S3 para a função do AWS Lambda no AWS IAM.\n",
        "\n",
        "> **Permissão FullAcessS3 concedida**\n",
        "\n",
        "![](https://github.com/murilovalenso/Projeto-Pipeline-de-Dados-Telegram/blob/main/Prints%201/21-permissaoEnriched.png?raw=true)"
      ],
      "metadata": {
        "id": "HqVUMNmRndWB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Recursos**\n",
        "\n",
        "O timeout padrão de funcões do AWS Lambda é de 3 segundos. Para a função, vamos aumentar o tempo para 5 minutos, principalmente para lidar com o IO (input/output) de arquivos do AWS S3.\n",
        "\n",
        "> **Alterado configuração para 5 minutos:**\n",
        "\n",
        "![](https://github.com/murilovalenso/Projeto-Pipeline-de-Dados-Telegram/blob/main/Prints%201/22-5min.png?raw=true)"
      ],
      "metadata": {
        "id": "vTK5IArhndWB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Camadas**\n",
        "\n",
        "Por fim, note que o código da função utiliza o pacote Python PyArrow. Contudo, o ambiente padrão do AWS Lambda possui poucos pacotes externos instalado, como o pacote Python boto3, logo o PyArrow não será encontrado e a execução da função falhará. Existem algumas formas de adicionar pacotes externos no ambiente de execução do AWS Lambda, um deles é a criação de camadas ou layers, onde podemos fazer o upload dos pacotes Python direto na plataforma ou através de um bucket do AWS S3. Vamos então seguir com a última opção, onde teremos que:\n",
        "\n",
        "* Criar um bucket no AWS S3;\n",
        "* Fazer o upload do código do pacote Python do PyArrow (download neste link);\n",
        "* Criar layer e conectar na função.\n",
        "\n",
        "> **Criação da camada**\n",
        "\n",
        "![](https://github.com/murilovalenso/Projeto-Pipeline-de-Dados-Telegram/blob/main/Prints%201/25-criacaodaLayer%20(3).png?raw=true)"
      ],
      "metadata": {
        "id": "qkRQo_lkndWC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.3 AWS Event Bridge**\n",
        "\n",
        "Na etapa de ETL, o AWS Event Bridge tem a função de ativar diariamente a fun\bção de ETL do AWS Lambda, funcionando assim como um scheduler.\n",
        "\n",
        "> **Nota**: Atente-se ao fato de que a função processa as mensagens do dia anterior (D-1).\n",
        "\n",
        "> **Regra no Event Bridge criada**\n",
        "\n",
        "![](https://github.com/murilovalenso/Projeto-Pipeline-de-Dados-Telegram/blob/main/Prints%201/30-eventBridge.png?raw=true)"
      ],
      "metadata": {
        "id": "qXDtBL1cndWC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.1 Apresentação\n",
        "\n",
        "A etapa de apresentação é reponsável por entregar o dado para os usuários (analistas, cientistas, etc.) e sistemas (dashboards, motores de consultas, etc.), idealmente através de uma interface de fácil uso, como o SQL, logo, essa é a única etapa que a maioria dos usuários terá acesso. Além disso, é importante que as ferramentas da etapa entregem dados armazenados em camadas refinadas, pois assim as consultas são mais baratas e o dados mais consistentes."
      ],
      "metadata": {
        "id": "saqyHEnDndWC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.1. AWS Athena**\n",
        "\n",
        "Na etapa de **apresentação**, o AWS Athena tem função de entregar o dados através de uma interface SQL para os usuários do sistema analítico. Para criar a interface, basta criar uma tabela externa sobre o dado armazenado na camada mais refinada da arquitetura, a camada enriquecida."
      ],
      "metadata": {
        "id": "MlK-kq-qndWC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Código para criar a tabela no Athena:**\n",
        "\n",
        "CREATE EXTERNAL TABLE `telegram`(\n",
        "  `message_id` bigint,\n",
        "  `user_id` bigint,\n",
        "  `user_is_bot` boolean,\n",
        "  `user_first_name` string,\n",
        "  `chat_id` bigint,\n",
        "  `chat_type` string,\n",
        "  `text` string,\n",
        "  `date` bigint)\n",
        "PARTITIONED BY (\n",
        "  `context_date` date)\n",
        "ROW FORMAT SERDE\n",
        "  'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'\n",
        "STORED AS INPUTFORMAT\n",
        "  'org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat'\n",
        "OUTPUTFORMAT\n",
        "  'org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat'\n",
        "LOCATION\n",
        "  's3://<bucket-enriquecido>/'"
      ],
      "metadata": {
        "id": "sbNC-_w2ndWD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Imagem da Tabela criada**\n",
        "\n",
        "![](https://github.com/murilovalenso/Projeto-Pipeline-de-Dados-Telegram/blob/main/Prints%201/31-criandoTabela%20(1).png?raw=true)"
      ],
      "metadata": {
        "id": "55NXlxqundWD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por fim, adicionei as partições disponíveis.\n",
        "\n",
        "> **Importante**: Toda vez que uma nova partição é adicionada ao repositório de dados, é necessário informar o AWS Athena para que a ela esteja disponível via SQL. Para isso, use o comando SQL MSCK REPAIR TABLE <nome-tabela> para todas as partições (mais caro) ou ALTER TABLE <nome-tabela> ADD PARTITION <coluna-partição> = <valor-partição> para uma única partição (mais barato), documentação neste link).\n",
        "    \n",
        "> **Código**\n",
        "    \n",
        "    MSCK REPAIR TABLE `telegram`;"
      ],
      "metadata": {
        "id": "PxCMI_DcndWE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Imagem da Query MSCK realizada**\n",
        "\n",
        "![](https://github.com/murilovalenso/Projeto-Pipeline-de-Dados-Telegram/blob/main/Prints%201/32-atualizandoTabela.png?raw=true)"
      ],
      "metadata": {
        "id": "Yv4ih3bsndWE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Consultei as 10 primeiras linhas para observar o resultado**\n",
        "\n",
        "Comando: SELECT * FROM `telegram` LIMIT 10;\n",
        "\n",
        "![](https://github.com/murilovalenso/Projeto-Pipeline-de-Dados-Telegram/blob/main/Prints%201/33-10primeirasLinhas.png?raw=true)"
      ],
      "metadata": {
        "id": "yjwqqSBUndWF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.2 Analytics**\n",
        "\n",
        "Com o dado disponível, usuário podem executar as mais variadas consultas analíticas. Seguem alguns exemplos:\n",
        "\n",
        "> **Quantidade de mensagens por dia.**\n",
        "\n",
        "![](https://github.com/murilovalenso/Projeto-Pipeline-de-Dados-Telegram/blob/main/Prints%201/34-qtdemsgspordia.png?raw=true)"
      ],
      "metadata": {
        "id": "pg4mRtdwndWF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Quantidade de mensagens por usuário por dia.**\n",
        "\n",
        "![](https://github.com/murilovalenso/Projeto-Pipeline-de-Dados-Telegram/blob/main/Prints%201/35-qtdemsgsporusuariopordia.png?raw=true)"
      ],
      "metadata": {
        "id": "A3FmGjwUndWF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Média do tamanho das mensagens por usuário por dia.**\n",
        "\n",
        "![](https://github.com/murilovalenso/Projeto-Pipeline-de-Dados-Telegram/blob/main/Prints%201/36-mediatamanhomsgsporusuariopordia.png?raw=true)"
      ],
      "metadata": {
        "id": "PKoYoakMndWG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Quantidade de mensagens por hora por dia da semana por número da semana.**\n",
        "\n",
        "![](https://github.com/murilovalenso/Projeto-Pipeline-de-Dados-Telegram/blob/main/Prints%201/37-qtde%20msgsporhorapor%20diadasemanapor%20n%C3%BAmerodasemana.png?raw=true)"
      ],
      "metadata": {
        "id": "be96NGNZndWH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Média do tamanho das mensagens**\n",
        "\n",
        "![](https://github.com/murilovalenso/Projeto-Pipeline-de-Dados-Telegram/blob/main/Prints%201/38-mediadotamdasmsgs.png?raw=true)"
      ],
      "metadata": {
        "id": "FSeMZjP8ndWH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Conclusão\n",
        "\n",
        "Utilizando o serviço do **AWS Athena** e queries em **SQL**, é possível extrair insights acerca das mensagens enviadas diariamente via Telegram."
      ],
      "metadata": {
        "id": "hDg5wO8NndWI"
      }
    }
  ]
}